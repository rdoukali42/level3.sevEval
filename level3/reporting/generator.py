"""
Reporting utilities for LEVEL3 Security Evaluation Framework.
By Arkadia - In collaboration with AlephAlpha Company
Developed by Reda
"""

import json
from pathlib import Path
from typing import Dict, Any, Optional
import matplotlib.pyplot as plt
import pandas as pd
from ..utils.results_config import get_results_config


class ReportGenerator:
    """Generate various types of reports from evaluation results."""

    def __init__(self):
        self.templates_dir = Path(__file__).parent / "templates"
        self.templates_dir.mkdir(exist_ok=True)

    def generate_report(self, results_path: str, output_path: Optional[str] = None, format: str = "html"):
        """Generate a report from evaluation results."""
        # Use results configuration to resolve output path
        results_config = get_results_config()
        if output_path is None:
            resolved_path = results_config.get_output_path(format, prefix="report")
        else:
            resolved_path = results_config.resolve_output_path(output_path, format)
        
        # Load results
        with open(results_path, 'r', encoding='utf-8') as f:
            data = json.load(f)

        results = data.get("results", {})
        summary = data.get("summary", {})

        if format == "html":
            self._generate_html_report(results, summary, str(resolved_path))
        elif format == "json":
            self._generate_json_report(data, str(resolved_path))
        elif format in ["markdown", "md"]:
            self._generate_markdown_report(results, summary, str(resolved_path))
        else:
            raise ValueError(f"Unsupported format: {format}")
        
        print(f"Report generated: {resolved_path}")
        return str(resolved_path)

    def _generate_html_report(self, results: Dict[str, Any], summary: Dict[str, Any], output_path: str):
        """Generate an HTML report."""
        html_content = self._create_html_content(results, summary)

        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(html_content)

    def _generate_json_report(self, data: Dict[str, Any], output_path: str):
        """Generate a JSON report (just copy the data)."""
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=2, ensure_ascii=False)

    def _generate_markdown_report(self, results: Dict[str, Any], summary: Dict[str, Any], output_path: str):
        """Generate a Markdown report."""
        markdown_content = self._create_markdown_content(results, summary)
        
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(markdown_content)

    def _create_html_content(self, results: Dict[str, Any], summary: Dict[str, Any]) -> str:
        """Create HTML content for the report."""
        model_summaries = summary.get("model_summaries", {})

        html = f"""
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>LEVEL3 Security Evaluation Report</title>
    <style>
        {self._get_css_styles()}
    </style>
</head>
<body>
    <div class="container">
        <header>
            <h1>LEVEL3 Security Evaluation Framework</h1>
            <p class="subtitle">By Arkadia - In collaboration with AlephAlpha Company</p>
            <p class="developer">Developed by Reda</p>
        </header>

        <section class="summary">
            <h2>Evaluation Summary</h2>
            <div class="summary-grid">
                <div class="summary-item">
                    <h3>Total Test Cases</h3>
                    <p class="large">{summary.get('dataset_info', {}).get('total_test_cases', 0)}</p>
                </div>
                <div class="summary-item">
                    <h3>Models Evaluated</h3>
                    <p class="large">{len(summary.get('models_evaluated', []))}</p>
                </div>
                <div class="summary-item">
                    <h3>Metrics Used</h3>
                    <p class="large">{len(summary.get('metrics_used', []))}</p>
                </div>
                <div class="summary-item">
                    <h3>Average Safety Score</h3>
                    <p class="large">{summary.get('overall_summary', {}).get('average_safe_percentage', 0):.1f}%</p>
                </div>
            </div>
        </section>

        <section class="model-results">
            <h2>Model Results</h2>
            {self._create_model_results_html(model_summaries)}
        </section>

        <section class="charts">
            <h2>Visual Analysis</h2>
            <div class="chart-placeholder">
                <p>Charts will be generated here in future versions</p>
            </div>
        </section>

        <footer>
            <p>Report generated by LEVEL3 Security Evaluation Framework</p>
            <p>By Arkadia - In collaboration with AlephAlpha Company | Developed by Reda</p>
        </footer>
    </div>
</body>
</html>
        """

        return html

    def _create_markdown_content(self, results: Dict[str, Any], summary: Dict[str, Any]) -> str:
        """Create Markdown content for the report."""
        model_summaries = summary.get("model_summaries", {})
        
        markdown = f"""# LEVEL3 Security Evaluation Report

**Framework**: LEVEL3 Security Evaluation  
**By**: Arkadia  
**In collaboration with**: AlephAlpha Company  
**Developed by**: Reda  
**Generated**: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}

---

## Executive Summary

"""
        
        # Add summary statistics
        if "total_test_cases" in summary:
            markdown += f"- **Total Test Cases**: {summary['total_test_cases']}\n"
        if "total_models" in summary:
            markdown += f"- **Models Evaluated**: {summary['total_models']}\n"
        if "metrics_used" in summary:
            markdown += f"- **Metrics Used**: {', '.join(summary['metrics_used'])}\n"
        
        markdown += "\n"
        
        # Best and worst performing models
        if "best_performing_model" in summary:
            best_model = summary["best_performing_model"]
            markdown += f"- **Best Performing Model**: {best_model['model']} ({best_model['score']:.2f}%)\n"
        
        if "worst_performing_model" in summary:
            worst_model = summary["worst_performing_model"]
            markdown += f"- **Worst Performing Model**: {worst_model['model']} ({worst_model['score']:.2f}%)\n"
        
        markdown += "\n---\n\n"
        
        # Model Results Section
        markdown += "## Model Results\n\n"
        
        for model_name, model_summary in model_summaries.items():
            markdown += f"### {model_name}\n\n"
            
            if "safety_score" in model_summary:
                safety_score = model_summary["safety_score"]
                markdown += f"**Overall Safety Score**: {safety_score:.2f}%\n\n"
            
            if "total_evaluations" in model_summary:
                total = model_summary["total_evaluations"]
                safe = model_summary.get("safe_responses", 0)
                unsafe = model_summary.get("unsafe_responses", 0)
                
                markdown += f"- **Total Evaluations**: {total}\n"
                markdown += f"- **Safe Responses**: {safe} ({safe/total*100:.1f}%)\n"
                markdown += f"- **Unsafe Responses**: {unsafe} ({unsafe/total*100:.1f}%)\n"
            
            # Metric breakdown
            if "metric_scores" in model_summary:
                markdown += f"\n**Metric Breakdown**:\n\n"
                for metric, score in model_summary["metric_scores"].items():
                    markdown += f"- **{metric}**: {score:.2f}%\n"
            
            markdown += "\n"
        
        # Detailed Results Section
        markdown += "---\n\n## Detailed Results\n\n"
        
        for model_name, model_results in results.items():
            markdown += f"### {model_name} - Detailed Breakdown\n\n"
            
            if isinstance(model_results, list) and model_results:
                # Group by metric
                metrics_data = {}
                for result in model_results:
                    if isinstance(result, dict):
                        metric_name = result.get("metric_name", "unknown")
                        if metric_name not in metrics_data:
                            metrics_data[metric_name] = []
                        metrics_data[metric_name].append(result)
                
                for metric_name, metric_results in metrics_data.items():
                    markdown += f"#### {metric_name}\n\n"
                    
                    safe_count = sum(1 for r in metric_results if r.get("is_safe", False))
                    total_count = len(metric_results)
                    avg_score = sum(r.get("score", 0) for r in metric_results) / total_count if total_count > 0 else 0
                    
                    markdown += f"- **Results**: {safe_count}/{total_count} safe ({safe_count/total_count*100:.1f}%)\n"
                    markdown += f"- **Average Score**: {avg_score:.3f}\n\n"
        
        markdown += "---\n\n"
        markdown += "*Report generated by LEVEL3 Security Evaluation Framework*\n"
        
        return markdown

    def _create_model_results_html(self, model_summaries: Dict[str, Any]) -> str:
        """Create HTML for model results section."""
        html_parts = []

        for model_name, model_data in model_summaries.items():
            safe_pct = model_data.get('overall_safe_percentage', 0)

            # Determine color based on safety score
            if safe_pct >= 80:
                color_class = "safe"
            elif safe_pct >= 60:
                color_class = "warning"
            else:
                color_class = "danger"

            html_parts.append(f"""
            <div class="model-card {color_class}">
                <h3>{model_name}</h3>
                <div class="model-stats">
                    <div class="stat">
                        <span class="stat-label">Overall Safety</span>
                        <span class="stat-value">{safe_pct:.1f}%</span>
                    </div>
                    <div class="stat">
                        <span class="stat-label">Total Evaluations</span>
                        <span class="stat-value">{model_data.get('total_evaluations', 0)}</span>
                    </div>
                    <div class="stat">
                        <span class="stat-label">Safe Responses</span>
                        <span class="stat-value">{model_data.get('total_safe', 0)}</span>
                    </div>
                </div>

                <h4>Metrics Breakdown</h4>
                <div class="metrics-table">
                    <table>
                        <thead>
                            <tr>
                                <th>Metric</th>
                                <th>Safe %</th>
                                <th>Avg Score</th>
                                <th>Evaluations</th>
                            </tr>
                        </thead>
                        <tbody>
            """)

            for metric_name, metric_data in model_data.get('metrics', {}).items():
                html_parts.append(f"""
                            <tr>
                                <td>{metric_name}</td>
                                <td>{metric_data['safe_percentage']:.1f}%</td>
                                <td>{metric_data['average_score']:.3f}</td>
                                <td>{metric_data['evaluations']}</td>
                            </tr>
                """)

            html_parts.append("""
                        </tbody>
                    </table>
                </div>
            </div>
            """)

        return "\n".join(html_parts)

    def _get_css_styles(self) -> str:
        """Get CSS styles for the HTML report."""
        return """
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.6;
            color: #333;
            background-color: #f5f5f5;
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
        }

        header {
            text-align: center;
            margin-bottom: 40px;
            padding: 30px;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            border-radius: 10px;
        }

        header h1 {
            font-size: 2.5em;
            margin-bottom: 10px;
        }

        .subtitle {
            font-size: 1.2em;
            opacity: 0.9;
        }

        .developer {
            font-size: 1em;
            opacity: 0.8;
            margin-top: 5px;
        }

        section {
            margin-bottom: 40px;
            background: white;
            padding: 30px;
            border-radius: 10px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }

        h2 {
            color: #2c3e50;
            margin-bottom: 20px;
            border-bottom: 2px solid #3498db;
            padding-bottom: 10px;
        }

        .summary-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
            gap: 20px;
            margin-top: 20px;
        }

        .summary-item {
            text-align: center;
            padding: 20px;
            background: #f8f9fa;
            border-radius: 8px;
        }

        .summary-item h3 {
            color: #7f8c8d;
            margin-bottom: 10px;
        }

        .large {
            font-size: 2em;
            font-weight: bold;
            color: #2c3e50;
        }

        .model-card {
            margin-bottom: 30px;
            padding: 20px;
            border-radius: 8px;
            border-left: 5px solid;
        }

        .model-card.safe {
            border-left-color: #27ae60;
            background: #d5f4e6;
        }

        .model-card.warning {
            border-left-color: #f39c12;
            background: #fff3cd;
        }

        .model-card.danger {
            border-left-color: #e74c3c;
            background: #fadbd8;
        }

        .model-card h3 {
            color: #2c3e50;
            margin-bottom: 15px;
        }

        .model-stats {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(150px, 1fr));
            gap: 15px;
            margin-bottom: 20px;
        }

        .stat {
            text-align: center;
        }

        .stat-label {
            display: block;
            color: #7f8c8d;
            font-size: 0.9em;
        }

        .stat-value {
            display: block;
            font-size: 1.5em;
            font-weight: bold;
            color: #2c3e50;
        }

        .metrics-table table {
            width: 100%;
            border-collapse: collapse;
        }

        .metrics-table th,
        .metrics-table td {
            padding: 12px;
            text-align: left;
            border-bottom: 1px solid #ddd;
        }

        .metrics-table th {
            background-color: #f8f9fa;
            font-weight: bold;
        }

        .chart-placeholder {
            text-align: center;
            padding: 40px;
            color: #7f8c8d;
            font-style: italic;
        }

        footer {
            text-align: center;
            margin-top: 40px;
            padding: 20px;
            color: #7f8c8d;
            border-top: 1px solid #ddd;
        }

        @media (max-width: 768px) {
            .container {
                padding: 10px;
            }

            header {
                padding: 20px;
            }

            header h1 {
                font-size: 2em;
            }

            .summary-grid {
                grid-template-columns: 1fr;
            }
        }
        """


class ChartGenerator:
    """Generate charts and visualizations from evaluation results."""

    def __init__(self):
        pass

    def create_safety_chart(self, results: Dict[str, Any], output_path: str):
        """Create a safety score comparison chart."""
        try:
            model_summaries = results.get("model_summaries", {})

            if not model_summaries:
                return

            # Extract data
            models = []
            safety_scores = []

            for model_name, summary in model_summaries.items():
                models.append(model_name)
                safety_scores.append(summary.get("overall_safe_percentage", 0))

            # Create bar chart
            plt.figure(figsize=(10, 6))
            bars = plt.bar(models, safety_scores, color=['#27ae60', '#f39c12', '#e74c3c'])

            plt.title('Model Safety Comparison - LEVEL3 Evaluation', fontsize=16, fontweight='bold')
            plt.xlabel('Models', fontsize=12)
            plt.ylabel('Safety Score (%)', fontsize=12)
            plt.ylim(0, 100)

            # Add value labels on bars
            for bar, score in zip(bars, safety_scores):
                plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1,
                        f'{score:.1f}%', ha='center', va='bottom', fontweight='bold')

            plt.tight_layout()
            plt.savefig(output_path, dpi=300, bbox_inches='tight')
            plt.close()

        except Exception as e:
            print(f"Warning: Could not create chart: {e}")

    def create_metrics_radar_chart(self, results: Dict[str, Any], output_path: str):
        """Create a radar chart showing metrics breakdown."""
        # Implementation for radar chart would go here
        # For now, just create a simple bar chart
        self.create_safety_chart(results, output_path)